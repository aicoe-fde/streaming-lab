{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at the sentiment of some example text from Jane Austen (we picked a notably recognizable excerpt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletext = \"\"\" It is a truth universally acknowledged, that a single man in possession\n",
    "of a good fortune, must be in want of a wife.\n",
    "\n",
    "However little known the feelings or views of such a man may be on his\n",
    "first entering a neighbourhood, this truth is so well fixed in the minds\n",
    "of the surrounding families, that he is considered the rightful property\n",
    "of some one or other of their daughters. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = english(sampletext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'neg': 0.0, 'neu': 0.711, 'pos': 0.289, 'compound': 0.6705},\n",
       " {'neg': 0.0, 'neu': 0.895, 'pos': 0.105, 'compound': 0.6147}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[analyzer.polarity_scores(str(s)) for s in list(result.sents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the first two sentences of _Pride and Prejudice_ score as pretty neutral.  Let's try some raw text from the negative product reviews corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[( This oatmeal is not good.,\n",
       "  {'neg': 0.376, 'neu': 0.624, 'pos': 0.0, 'compound': -0.3412}),\n",
       " (Its mushy, soft, I don't like it.,\n",
       "  {'neg': 0.297, 'neu': 0.703, 'pos': 0.0, 'compound': -0.2755}),\n",
       " (Quaker Oats is the way to go. \n",
       "  , {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}),\n",
       " (Seriously this product was as tasteless as they come.,\n",
       "  {'neg': 0.175, 'neu': 0.825, 'pos': 0.0, 'compound': -0.1779}),\n",
       " (There are much better tasting products out \n",
       "  there but at 100 calories its better than a special k bar or cookie snack pack.,\n",
       "  {'neg': 0.0, 'neu': 0.658, 'pos': 0.342, 'compound': 0.8537}),\n",
       " (You just have to \n",
       "  season it or combine it with something else to share the flavor.\n",
       "  , {'neg': 0.0, 'neu': 0.872, 'pos': 0.128, 'compound': 0.296}),\n",
       " (These were nasty, they were so greasy and too rich for my blood, plus they lacked major flavor, \n",
       "  no spicy jalapeno flavor at all.,\n",
       "  {'neg': 0.191, 'neu': 0.691, 'pos': 0.118, 'compound': -0.296})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = english(\"\"\" This oatmeal is not good. Its mushy, soft, I don't like it. Quaker Oats is the way to go. \n",
    "\n",
    "Seriously this product was as tasteless as they come. There are much better tasting products out \n",
    "there but at 100 calories its better than a special k bar or cookie snack pack. You just have to \n",
    "season it or combine it with something else to share the flavor.\n",
    "\n",
    "These were nasty, they were so greasy and too rich for my blood, plus they lacked major flavor, \n",
    "no spicy jalapeno flavor at all.\n",
    "\"\"\")\n",
    "[(s, analyzer.polarity_scores(str(s))) for s in list(negative.sents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll connect this sort of analysis to Spark so we can apply it to streaming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SPARK_VERSION=\"2.2.0\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--packages org.apache.spark:spark-sql-kafka-0-10_2.11:%s pyspark-shell\" % SPARK_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"Social Firehose\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.functions import column, from_json\n",
    "\n",
    "structure = StructType([StructField(fn, StringType(), True) for fn in \"text user_id update_id\".split()])\n",
    "\n",
    "records = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka.kafka.svc:9092\") \\\n",
    "  .option(\"subscribe\", \"social-firehose\") \\\n",
    "  .load() \\\n",
    "  .select(column(\"value\").cast(StringType()).alias(\"value\")) \\\n",
    "  .select(from_json(column(\"value\"), structure).alias(\"json\")) \\\n",
    "  .select(column(\"json.update_id\"), column(\"json.user_id\").alias(\"user_id\"), column(\"json.text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is borrowed from Sparkling Pandas; see here:\n",
    "# https://github.com/sparklingpandas/sparklingml/blob/627c8f23688397a53e2e9e805e92a54c2be1cf3d/sparklingml/transformation_functions.py#L53\n",
    "class SpacyMagic(object):\n",
    "    \"\"\"\n",
    "    Simple Spacy Magic to minimize loading time.\n",
    "    >>> SpacyMagic.get(\"en\")\n",
    "    <spacy.en.English ...\n",
    "    \"\"\"\n",
    "    _spacys = {}\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, lang):\n",
    "        if lang not in cls._spacys:\n",
    "            import spacy\n",
    "            cls._spacys[lang] = spacy.load(lang)\n",
    "        return cls._spacys[lang]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a user-defined function to split social-media updates into sentences.  We will use spaCy, which is more expensive than most reasonable heuristics for splitting text into sentences (but also much smarter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def split_sentences_impl(s):\n",
    "    \"\"\" splits an English string into sentences, using spaCy \"\"\"\n",
    "    english = SpacyMagic.get(\"en\")\n",
    "    return [str(sentence) for sentence in english(s).sents]\n",
    "\n",
    "split_sentences = udf(split_sentences_impl, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what this looks like, we'll run it on the first 10 rows of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(update_id='00000000000000000000', user_id='4665560161', sentences=[\"Elinor wished that the same forbearance could have extended towards herself, but that was impossible, and she was necessarily drawn from the mother's description.\", '#socialmedia #marketing #yolo']),\n",
       " Row(update_id='00000000000000000000', user_id='1000040647', sentences=['It did not suit her situation or feelings, I might have rejoiced in its termination.', '#tbt #fail #yolo']),\n",
       " Row(update_id='00000000000000000000', user_id='9086078734', sentences=['The furniture was in all probability have gained some news of them; and till we know that she ever should receive another so perfectly gratifying in the occasion and the style.', '#retweet #yolo #ff']),\n",
       " Row(update_id='00000000000000000001', user_id='3082369400', sentences=['After this period every appearance of equal permanency.', '#health']),\n",
       " Row(update_id='00000000000000000001', user_id='5902440326', sentences=['Her performance was pleasing, though by no means tired of wondering and admiring; and not even #Louisa seemed to feel all the tenderness of the past.', '#socialmedia #blogpost']),\n",
       " Row(update_id='00000000000000000001', user_id='3359902759', sentences=['These have NO hydrogenated oils, are fresh and taste delicious.', '#marketing #followfriday #tbt']),\n",
       " Row(update_id='00000000000000000002', user_id='0099016619', sentences=['The post-office has a great desire to see Mr. #Bingley.']),\n",
       " Row(update_id='00000000000000000002', user_id='7761320665', sentences=['Worse than all!', '#health #news']),\n",
       " Row(update_id='00000000000000000002', user_id='8304162681', sentences=['I could not help affronting them.', '#health #retweet']),\n",
       " Row(update_id='00000000000000000003', user_id='2529702535', sentences=['She is netting herself the sweetest cloak you can conceive.', '#ff'])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_records = records \\\n",
    "  .orderBy(\"update_id\") \\\n",
    "  .limit(10) \\\n",
    "  .select(\"update_id\", \"user_id\", split_sentences(column(\"text\")).alias(\"sentences\")) \\\n",
    "  .cache()\n",
    "\n",
    "split_records.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explode each array into multiple rows to make further processing easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|update_id           |user_id   |sentence                                                                                                                                                                        |\n",
      "+--------------------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|00000000000000000000|4665560161|Elinor wished that the same forbearance could have extended towards herself, but that was impossible, and she was necessarily drawn from the mother's description.              |\n",
      "|00000000000000000000|4665560161|#socialmedia #marketing #yolo                                                                                                                                                   |\n",
      "|00000000000000000000|1000040647|It did not suit her situation or feelings, I might have rejoiced in its termination.                                                                                            |\n",
      "|00000000000000000000|1000040647|#tbt #fail #yolo                                                                                                                                                                |\n",
      "|00000000000000000000|9086078734|The furniture was in all probability have gained some news of them; and till we know that she ever should receive another so perfectly gratifying in the occasion and the style.|\n",
      "|00000000000000000000|9086078734|#retweet #yolo #ff                                                                                                                                                              |\n",
      "|00000000000000000001|3082369400|After this period every appearance of equal permanency.                                                                                                                         |\n",
      "|00000000000000000001|3082369400|#health                                                                                                                                                                         |\n",
      "|00000000000000000001|5902440326|Her performance was pleasing, though by no means tired of wondering and admiring; and not even #Louisa seemed to feel all the tenderness of the past.                           |\n",
      "|00000000000000000001|5902440326|#socialmedia #blogpost                                                                                                                                                          |\n",
      "|00000000000000000001|3359902759|These have NO hydrogenated oils, are fresh and taste delicious.                                                                                                                 |\n",
      "|00000000000000000001|3359902759|#marketing #followfriday #tbt                                                                                                                                                   |\n",
      "|00000000000000000002|0099016619|The post-office has a great desire to see Mr. #Bingley.                                                                                                                         |\n",
      "|00000000000000000002|7761320665|Worse than all!                                                                                                                                                                 |\n",
      "|00000000000000000002|7761320665|#health #news                                                                                                                                                                   |\n",
      "|00000000000000000002|8304162681|I could not help affronting them.                                                                                                                                               |\n",
      "|00000000000000000002|8304162681|#health #retweet                                                                                                                                                                |\n",
      "|00000000000000000003|2529702535|She is netting herself the sweetest cloak you can conceive.                                                                                                                     |\n",
      "|00000000000000000003|2529702535|#ff                                                                                                                                                                             |\n",
      "+--------------------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "sentences = split_records.select(\"update_id\", \"user_id\", explode(column(\"sentences\")).alias(\"sentence\"))\n",
    "sentences.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "sentiment_fields = \"pos neg neu compound\".split()\n",
    "sentiment_structure = StructType([StructField(fn, FloatType(), True) for fn in sentiment_fields])\n",
    "\n",
    "analyzer_bcast = spark.sparkContext.broadcast(analyzer)\n",
    "\n",
    "def vader_impl(s):\n",
    "    va = analyzer_bcast.value\n",
    "    result = va.polarity_scores(s)\n",
    "    return [result[key] for key in sentiment_fields]\n",
    "\n",
    "sentiment_score = udf(vader_impl, sentiment_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+\n",
      "|           update_id|   user_id|            sentence|vader_impl(sentence)|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "|00000000000000000000|4665560161|Elinor wished tha...|   [0.0,0.0,1.0,0.0]|\n",
      "|00000000000000000000|4665560161|#socialmedia #mar...|   [0.0,0.0,1.0,0.0]|\n",
      "|00000000000000000000|1000040647|It did not suit h...|[0.188,0.0,0.812,...|\n",
      "|00000000000000000000|1000040647|    #tbt #fail #yolo|   [0.0,0.0,1.0,0.0]|\n",
      "|00000000000000000000|9086078734|The furniture was...|[0.292,0.0,0.708,...|\n",
      "|00000000000000000000|9086078734|  #retweet #yolo #ff|   [0.0,0.0,1.0,0.0]|\n",
      "|00000000000000000001|3082369400|After this period...|   [0.0,0.0,1.0,0.0]|\n",
      "|00000000000000000001|3082369400|             #health|   [0.0,0.0,1.0,0.0]|\n",
      "|00000000000000000001|5902440326|Her performance w...|[0.252,0.146,0.60...|\n",
      "|00000000000000000001|5902440326|#socialmedia #blo...|   [0.0,0.0,1.0,0.0]|\n",
      "|00000000000000000001|3359902759|These have NO hyd...|[0.377,0.184,0.43...|\n",
      "|00000000000000000001|3359902759|#marketing #follo...|   [0.0,0.0,1.0,0.0]|\n",
      "|00000000000000000002|0099016619|The post-office h...|[0.493,0.0,0.507,...|\n",
      "|00000000000000000002|7761320665|     Worse than all!|[0.0,0.629,0.371,...|\n",
      "|00000000000000000002|7761320665|       #health #news|   [0.0,0.0,1.0,0.0]|\n",
      "|00000000000000000002|8304162681|I could not help ...|[0.0,0.361,0.639,...|\n",
      "|00000000000000000002|8304162681|    #health #retweet|   [0.0,0.0,1.0,0.0]|\n",
      "|00000000000000000003|2529702535|She is netting he...|   [0.0,0.0,1.0,0.0]|\n",
      "|00000000000000000003|2529702535|                 #ff|   [0.0,0.0,1.0,0.0]|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences.select(\"update_id\", \"user_id\", \"sentence\", sentiment_score(column(\"sentence\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
